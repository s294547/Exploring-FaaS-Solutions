configurazione: credenziali servizio segreto azure functions
devo fare u
parametri di avvio --> puntamento, valore stringa generica + un parametro di tipo segreto, devo trovare un modo per mettere insieme queste cose in maniera scalabile. 
questa faas deve girare con questi param, sia secret che non --> come gestisco questa configurazione?

casi d'uso: misurazione temperature, umidità data center
		temperature - umidità agricoltura 
		sensori sonori
		
            casa
		
np iot --> protocollo 
domotic iot faas. 


facciamo un dispositivo che fa una publish su un tpoic e facciamo l'innesco della function da qualche parte. 1^fase) uguale al pezzo blu  2^ fase) avremo un grosso db con miliardi di record, che possono essere salvati in un punto a caso. Ho un container, lo interrrogo e gli dico mi serve per quel data center la media dell'ultimo giorno? a quel punto scatta la faas, che mi fa la preelaborazione e la salva. 
le funzioni che devono essere eseguite, sono recuperabili in maniera remota e in maniera centralizzata?
openwhisk ha il suo db ho ha bisogno del suo db  

1) smontare openwhisk, prendo nchart e devo trovare un tipo di configurazione in cui c'è la configurazione del puntamento al db. Poi m
perndo installazione couchdb e provo a deployare couchdb e basta in un altro namespace, poi provo a far puntare openwhisk 

o openwhisk in ogni data center che si collega a un couchdb remoto. 
nice to have: la freccetta blu è sempre rivolta.  

esp 32

 helm install couchdb/couchdb  --version=4.1.0  --set allowAdminParty=true   --set couchdbConfig.couchdb.uuid=$(curl https://www.uuidgenerator.net/api/version4 2>/dev/null | tr -d -)


                "/bin/bash",
                "-c",
                "cd KafkaFeedProvider && python -u app.py"

4064897

Yes, each instance of OpenWhisk in your two clusters will have its own datastore cache. The datastore cache is a local caching layer that sits between the functions and the remote database, and is specific to each OpenWhisk instance.

When a function running on one instance of OpenWhisk accesses the remote database, the data it retrieves is stored in the datastore cache of that instance. If the same function is later invoked on the same instance and requests the same data, the data can be returned from the cache instead of being retrieved from the remote database, which can improve performance.

However, if a function is invoked on a different instance of OpenWhisk than the one it was previously executed on, the data store cache on that instance will not have a copy of the previously retrieved data. Therefore, the function will need to retrieve the data from the remote database again, and the data will be cached in the datastore cache of that instance.

In summary, each instance of OpenWhisk has its own datastore cache, which is specific to that instance and is not shared with other instances.




yukikuran99@yahoo.it
So the datastore cache is not in the remote db, but in the cluster where i have my openwhisk oinstance.
Yes, that's correct. The datastore cache in OpenWhisk is a local caching layer that is located in the same cluster as the OpenWhisk instance that is using it. The cache is designed to reduce the number of requests made to the remote database by storing frequently accessed data in memory on the local cluster.

When a function running on an OpenWhisk instance needs to access data from the remote database, the datastore cache first checks if the data is already stored in the cache. If the data is present in the cache, it is returned to the function without the need to make a request to the remote database. If the data is not present in the cache, the cache retrieves the data from the remote database and stores it in the cache for future requests.

The datastore cache is specific to each OpenWhisk instance and is not shared between instances. This means that each OpenWhisk instance maintains its own cache, and data cached on one instance is not available on another instance.